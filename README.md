# st-gem - Link Scraper

A robust and polite **Python-based web link scraper** that extracts all hyperlinks (`<a href="">`) from a given webpage â€” or crawls an entire site up to a configurable depth.  

It supports domain filtering, robot.txt compliance, retries, timeouts, rate limiting, and multiple output formats (CSV, JSON, TXT).

---

## ðŸš€ Features

âœ… Extracts all hyperlinks (`<a>` tags) from any HTML page  
âœ… Optionally **crawls multiple pages** up to a given depth (BFS traversal)  
âœ… **Respects `robots.txt`** directives  
âœ… Deduplicates and normalizes URLs  
âœ… Supports **same-domain-only** filtering (with or without subdomains)  
âœ… Polite crawling with optional **delay between requests**  
âœ… Export results as **CSV**, **JSON**, or **TXT**  
âœ… Clean CLI and well-structured output  

---

## ðŸ§° Requirements

- Python 3.8+
- The following libraries:
  ```bash
  pip install requests beautifulsoup4
  ```
